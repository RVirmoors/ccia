---
layout: presentation
title: The Max for Live API
---

class: center, middle
.title[Interactive Music Systems]
<br/><br/>
.subtitle[The Max for Live API]
<br/><br/><br/><br/><br/><br/>
.date[Nov 2022] 
<br/><br/><br/>
.note[Created with [Liminal](https://github.com/jonathanlilly/liminal) using [Remark.js](http://remarkjs.com/) + [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) + [KaTeX](https://katex.org)]

???

Author: Grigore Burloiu, UNATC
    
---
name: toc
class: left
# ★ Table of Contents ★     <!-- omit in toc -->

1. [Ableton Live](#ableton-live)
2. [The Live API](#the-live-api)
3. [Example](#example)
4. [Assignment](#assignment)

        
<!-- Comment out the next slide if you don't want the Table of Contents link -->         
---
layout: true  .toc[[★](#toc)]
        
---
name: ableton-live
# Ableton Live

tracks
- clips

--
- devices
  - effects (audio / midi input&output)
  - instruments (midi input, audio output)

--

scenes

--

views

---
## Basic shortcuts

| TAB | switch *session* / *arrangement* view |
|-|-----------|
| Shift-TAB |  show effect chain / [audio or midi] clip |
|double-click|        new clip (in session view), new event (in MIDI clip)|
|ctrl-D / alt-drag|    duplicate|
|ctrl-drag|            adjust note velocity|
|F10|            back to arrangement|

---
## Controlling Ableton via MIDI

.left-column[
<img style="width:100%"  src="../attachments/live-midi1.png">
]

.right-column[<br/>
<img style="width:100%"  src="../attachments/live-midi3.png">
]

<img style="width:100%"  src="../attachments/live-midi2.png">

---
## Max & Live integration

Live handles audio+MIDI in & out to M4L devices

[timing](https://docs.cycling74.com/max8/vignettes/live_timing): Max transport is led by Live   

Max values can be Live [parameters](https://docs.cycling74.com/max8/vignettes/live_parameters) (for automation, presets etc)

factory M4L [abstractions](https://docs.cycling74.com/max8/vignettes/live_abstractions) 

more: 
- https://docs.cycling74.com/max8/vignettes/doclive
- https://docs.cycling74.com/max8/vignettes/live_limitations 

---
name: the-live-api
# The Live API

[control Live from Max](https://docs.cycling74.com/max8/vignettes/live_api_overview): transport, tracks, clips, ...

<img style="width:75%"  src="../attachments/live-remote-api.png">

- [Live API + JS](https://docs.cycling74.com/max8/vignettes/jsliveapi)
- find `live.path` using the [Live Object Model](https://docs.cycling74.com/max8/vignettes/live_object_model)

--
- ... or simply use the [M4L API abstractions](https://docs.cycling74.com/max8/vignettes/live_apiabstractions)

---
# Example

2 scenes: `listen`, `play`

- ☐ - `listen` = learns a Markov chain (notes+durations)
- ☒ - `play` = generates notes using Markov chain

--

switch between scenes when musician stays silent for n beats

--

is this an IMS?

---
## see also

<iframe width="100%" height="500" src="https://www.youtube.com/embed/yW8PkIl4tDE" title="C'est pour ça - [Extract] "Generative improvisation #1"" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

---
name: assignment
# Assignment

modify the `m4l-jam` project (or create a new one) which implements, at least:
- a `listen` scene and a `jam` scene
- switching between them based on machine listening and/or playing

OR

choose a [NIME paper](https://www.nime.org/archives/) and review it:
- 3 paragraphs / 600-700 words
- context + what you found interesting (NOT taken from abstract)